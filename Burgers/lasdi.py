#!/usr/bin/env python3
#type.ignore
"""Baseline LaSDI workflow for 1D Burgers.

This script trains:
  1) an auto-encoder on full-order snapshots
  2) per-parameter latent dynamics via SINDy (strong form)
  3) simple kNN interpolation of SINDy coefficients for prediction

It assumes datasets generated by burgers_simulation.py --dataset-dir.
"""

from __future__ import annotations

import argparse
import json
import math
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import TYPE_CHECKING, Iterable, List, Sequence, Tuple

import numpy as np
from tqdm import tqdm

SCRIPT_DIR = Path(__file__).resolve().parent
if str(SCRIPT_DIR) not in sys.path:
    sys.path.insert(0, str(SCRIPT_DIR))

from burgers_simulation import initial_condition  # noqa: E402


GRID_SAMPLES_PER_AXIS = 5
LEARNING_CASES = GRID_SAMPLES_PER_AXIS * GRID_SAMPLES_PER_AXIS
DEFAULT_DATASET_DIR = SCRIPT_DIR / "dataset"
DEFAULT_MODEL_DIR = SCRIPT_DIR / "lasdi_model"

try:
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, TensorDataset
except Exception as exc:  # pragma: no cover - runtime dependency
    torch = None
    nn = None
    DataLoader = None
    TensorDataset = None
    TORCH_IMPORT_ERROR = exc
else:
    TORCH_IMPORT_ERROR = None

if TYPE_CHECKING:  # pragma: no cover - typing only
    import torch as torch_typing


@dataclass
class AEConfig:
    input_dim: int
    latent_dim: int
    hidden_sizes: Sequence[int]
    activation: str


@dataclass
class TrainConfig:
    epochs: int = 5000
    batch_size: int = 512
    lr: float = 1.0e-3
    weight_decay: float = 1.0e-6
    time_stride: int = 1
    drop_endpoint: bool = False
    sindy_degree: int = 1
    sindy_threshold: float = 0.05
    sindy_max_iter: int = 10
    sindy_ridge: float = 1.0e-5


class AutoEncoder(nn.Module):
    def __init__(self, cfg: AEConfig):
        super().__init__()
        act = activation_from_name(cfg.activation)
        enc_layers: List["torch_typing.nn.Module"] = []
        in_dim = cfg.input_dim
        for h in cfg.hidden_sizes:
            enc_layers.append(nn.Linear(in_dim, h))
            enc_layers.append(act())
            in_dim = h
        enc_layers.append(nn.Linear(in_dim, cfg.latent_dim))
        self.encoder = nn.Sequential(*enc_layers)

        dec_layers: List["torch_typing.nn.Module"] = []
        in_dim = cfg.latent_dim
        for h in reversed(cfg.hidden_sizes):
            dec_layers.append(nn.Linear(in_dim, h))
            dec_layers.append(act())
            in_dim = h
        dec_layers.append(nn.Linear(in_dim, cfg.input_dim))
        self.decoder = nn.Sequential(*dec_layers)

    def encode(self, x: torch.Tensor) -> torch.Tensor: # type: ignore
        return self.encoder(x)

    def decode(self, z: torch.Tensor) -> torch.Tensor: # type: ignore
        return self.decoder(z)

    def forward(self, x: torch.Tensor) -> torch.Tensor: # type: ignore
        return self.decode(self.encode(x))


def activation_from_name(name: str):
    name = name.lower()
    if name == "sigmoid":
        return nn.Sigmoid
    if name == "tanh":
        return nn.Tanh
    if name == "relu":
        return nn.ReLU
    raise ValueError(f"Unknown activation: {name}")


def require_torch() -> None:
    if torch is None:
        raise RuntimeError(
            "PyTorch is required for lasdi.py. "
            "Install torch before running this script."
        ) from TORCH_IMPORT_ERROR


def load_index(dataset_dir: Path) -> List[Tuple[str, float, float]]:
    index_path = dataset_dir / "index.csv"
    if not index_path.exists():
        raise FileNotFoundError(f"index.csv not found in {dataset_dir}")
    rows = []
    with index_path.open("r", encoding="utf-8") as handle:
        header = handle.readline()
        if "filename" not in header:
            raise ValueError("index.csv header is invalid")
        for line in handle:
            filename, a_str, w_str = line.strip().split(",")
            rows.append((filename, float(a_str), float(w_str)))
    return rows


def select_grid_rows(
    rows: Sequence[Tuple[str, float, float]],
) -> List[Tuple[str, float, float]]:
    if not rows:
        return []

    a_values = np.array(sorted({a for _, a, _ in rows}), dtype=float)
    w_values = np.array(sorted({w for _, _, w in rows}), dtype=float)
    a_idx = np.round(np.linspace(0, len(a_values) - 1, GRID_SAMPLES_PER_AXIS)).astype(int)
    w_idx = np.round(np.linspace(0, len(w_values) - 1, GRID_SAMPLES_PER_AXIS)).astype(int)
    # Keep order while removing duplicates if the grid is smaller than requested.
    a_idx = np.asarray(list(dict.fromkeys(a_idx.tolist())), dtype=int)
    w_idx = np.asarray(list(dict.fromkeys(w_idx.tolist())), dtype=int)
    target_a = a_values[a_idx]
    target_w = w_values[w_idx]
    targets = np.array([(a, w) for a in target_a for w in target_w], dtype=float)

    row_index_map = {(a, w): idx for idx, (_, a, w) in enumerate(rows)}
    params = np.asarray([[a, w] for _, a, w in rows], dtype=float)

    selected_idx: List[int] = []
    selected_set = set()
    for target in targets:
        idx_exact = row_index_map.get((float(target[0]), float(target[1])))
        if idx_exact is not None:
            idx_int = int(idx_exact)
            if idx_int not in selected_set:
                selected_idx.append(idx_int)
                selected_set.add(idx_int)
            continue

        # Fallback: nearest available case if an exact grid point is missing.
        dists = np.linalg.norm(params - target, axis=1)
        for idx in np.argsort(dists):
            idx_int = int(idx)
            if idx_int not in selected_set:
                selected_idx.append(idx_int)
                selected_set.add(idx_int)
                break

    # Fallback for degenerate or sparse parameter ranges.
    if len(selected_idx) < LEARNING_CASES:
        for idx in range(len(rows)):
            if idx not in selected_set:
                selected_idx.append(idx)
                selected_set.add(idx)
            if len(selected_idx) == LEARNING_CASES:
                break

    return [rows[idx] for idx in selected_idx]


def downsample_time(u: np.ndarray, t: np.ndarray, stride: int) -> Tuple[np.ndarray, np.ndarray]:
    if stride <= 1:
        return u, t
    return u[::stride], t[::stride]


def load_series(
    dataset_dir: Path, filename: str, drop_endpoint: bool, time_stride: int
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    data = np.load(dataset_dir / filename)
    u = data["u"]
    t = data["t"]
    x = data["x"]
    if drop_endpoint:
        u = u[:, :-1]
        x = x[:-1]
    u, t = downsample_time(u, t, time_stride)
    return x, t, u


def collect_snapshots(
    dataset_dir: Path,
    rows: Sequence[Tuple[str, float, float]],
    time_stride: int,
    drop_endpoint: bool,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    snapshots = []
    params = []
    x_ref = None
    t_ref = None
    for filename, a, w in rows:
        x, t, u = load_series(dataset_dir, filename, drop_endpoint, time_stride)
        if x_ref is None:
            x_ref = x
            t_ref = t
        snapshots.append(u)
        params.append([a, w])
    if not snapshots:
        raise RuntimeError("No snapshots loaded")
    u_all = np.vstack(snapshots)
    return np.asarray(params), x_ref, t_ref, u_all


def normalize_data(u: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    mean = u.mean(axis=0)
    std = u.std(axis=0)
    std[std < 1.0e-12] = 1.0
    u_norm = (u - mean) / std
    return u_norm, mean, std


def train_autoencoder(
    u_norm: np.ndarray,
    ae_cfg: AEConfig,
    train_cfg: TrainConfig,
    device: torch.device, # type: ignore
) -> AutoEncoder:
    require_torch()
    model = AutoEncoder(ae_cfg).to(device)
    dataset = TensorDataset(torch.from_numpy(u_norm).float())
    loader = DataLoader(dataset, batch_size=train_cfg.batch_size, shuffle=True)
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=train_cfg.lr,
        weight_decay=train_cfg.weight_decay,
    )
    loss_fn = nn.MSELoss()

    model.train()
    pbar = tqdm(range(train_cfg.epochs), desc="Training AutoEncoder")
    for epoch in pbar:
        running = 0.0
        for (batch,) in loader:
            batch = batch.to(device)
            optimizer.zero_grad()
            recon = model(batch)
            loss = loss_fn(recon, batch)
            loss.backward()
            optimizer.step()
            running += loss.item() * batch.size(0)
        avg = running / len(dataset)
        pbar.set_postfix({"loss": f"{avg:.6e}"})
    pbar.close()
    return model


def encode_series(
    model: AutoEncoder,
    u: np.ndarray,
    mean: np.ndarray,
    std: np.ndarray,
    device: torch.device, # type: ignore
    batch_size: int,
) -> np.ndarray:
    require_torch()
    model.eval()
    u_norm = (u - mean) / std
    z_list = []
    with torch.no_grad():
        for i in range(0, u_norm.shape[0], batch_size):
            batch = torch.from_numpy(u_norm[i : i + batch_size]).float().to(device)
            z = model.encode(batch).cpu().numpy()
            z_list.append(z)
    return np.vstack(z_list)


def build_terms(latent_dim: int, degree: int, include_constant: bool = True):
    terms = []
    if include_constant:
        terms.append(("1",))
    if degree >= 1:
        for i in range(latent_dim):
            terms.append(("z", i))
    if degree >= 2:
        for i in range(latent_dim):
            for j in range(i, latent_dim):
                terms.append(("zz", i, j))
    return terms


def term_names(terms) -> List[str]:
    names = []
    for term in terms:
        if term[0] == "1":
            names.append("1")
        elif term[0] == "z":
            names.append(f"z{term[1]}")
        elif term[0] == "zz":
            names.append(f"z{term[1]}*z{term[2]}")
    return names


def evaluate_terms(z: np.ndarray, terms) -> np.ndarray:
    values = np.empty(len(terms), dtype=z.dtype)
    for k, term in enumerate(terms):
        if term[0] == "1":
            values[k] = 1.0
        elif term[0] == "z":
            values[k] = z[term[1]]
        elif term[0] == "zz":
            values[k] = z[term[1]] * z[term[2]]
    return values


def build_library(z: np.ndarray, terms) -> np.ndarray:
    theta = np.empty((z.shape[0], len(terms)), dtype=z.dtype)
    for i in range(z.shape[0]):
        theta[i] = evaluate_terms(z[i], terms)
    return theta


def time_derivative(z: np.ndarray, dt: float) -> np.ndarray:
    dzdt = np.empty_like(z)
    dzdt[1:-1] = (z[2:] - z[:-2]) / (2.0 * dt)
    dzdt[0] = (z[1] - z[0]) / dt
    dzdt[-1] = (z[-1] - z[-2]) / dt
    return dzdt


def ridge_regression(theta: np.ndarray, dzdt: np.ndarray, ridge: float) -> np.ndarray:
    if ridge <= 0.0:
        return np.linalg.lstsq(theta, dzdt, rcond=None)[0]
    gram = theta.T @ theta
    rhs = theta.T @ dzdt
    reg = ridge * np.eye(gram.shape[0], dtype=theta.dtype)
    return np.linalg.solve(gram + reg, rhs)


def standardize_library(theta: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, int]:
    theta_mean = theta.mean(axis=0)
    theta_std = theta.std(axis=0)

    # Keep near-constant columns unchanged to avoid collapsing the constant term.
    variable = theta_std > 1.0e-12
    theta_scaled = theta.copy()
    theta_scaled[:, variable] = (theta[:, variable] - theta_mean[variable]) / theta_std[variable]
    theta_scaled[:, ~variable] = theta[:, ~variable]

    mean_eff = np.zeros_like(theta_mean)
    std_eff = np.ones_like(theta_std)
    mean_eff[variable] = theta_mean[variable]
    std_eff[variable] = theta_std[variable]

    const_idx = 0
    for j in range(theta.shape[1]):
        if np.allclose(theta[:, j], 1.0):
            const_idx = j
            break

    return theta_scaled, mean_eff, std_eff, const_idx


def unscale_coefficients(
    xi_scaled: np.ndarray,
    theta_mean: np.ndarray,
    theta_std: np.ndarray,
    const_idx: int,
) -> np.ndarray:
    xi = xi_scaled / theta_std[:, None]
    mean_shift = ((theta_mean / theta_std)[:, None] * xi_scaled).sum(axis=0)
    xi[const_idx] -= mean_shift
    return xi


def stlsq(
    theta: np.ndarray,
    dzdt: np.ndarray,
    threshold: float,
    max_iter: int,
    ridge: float,
) -> np.ndarray:
    theta_scaled, theta_mean, theta_std, const_idx = standardize_library(theta)
    xi = ridge_regression(theta_scaled, dzdt, ridge)
    for _ in range(max_iter):
        small = np.abs(xi) < threshold
        xi[small] = 0.0
        for k in range(xi.shape[1]):
            big = ~small[:, k]
            if not np.any(big):
                continue
            xi[big, k] = ridge_regression(theta_scaled[:, big], dzdt[:, k], ridge)
    return unscale_coefficients(xi, theta_mean, theta_std, const_idx)


def fit_sindy(
    z: np.ndarray,
    dt: float,
    degree: int,
    threshold: float,
    max_iter: int,
    ridge: float,
    z_mean: np.ndarray | None = None,
    z_std: np.ndarray | None = None,
):
    if z_mean is None:
        z_mean = z.mean(axis=0)
    if z_std is None:
        z_std = z.std(axis=0)
    z_std = np.maximum(z_std, 1.0e-8)
    z_hat = (z - z_mean) / z_std
    terms = build_terms(z.shape[1], degree)
    theta = build_library(z_hat, terms)
    dzdt = time_derivative(z_hat, dt)
    xi = stlsq(theta, dzdt, threshold, max_iter, ridge)
    return xi, terms


def knn_indices_weights(
    params: np.ndarray,
    target: np.ndarray,
    k: int,
) -> Tuple[np.ndarray, np.ndarray]:
    params_min = params.min(axis=0)
    params_span = params.max(axis=0) - params_min
    params_span[params_span < 1.0e-12] = 1.0
    params_norm = (params - params_min) / params_span
    target_norm = (target - params_min) / params_span
    dists = np.linalg.norm(params_norm - target_norm, axis=1)

    if k <= 1 or params.shape[0] == 1:
        idx = int(np.argmin(dists))
        return np.array([idx], dtype=int), np.array([1.0], dtype=float)

    idx = np.argsort(dists)[:k].astype(int)
    weights = 1.0 / (dists[idx] ** 2 + 1.0e-12)
    weights /= weights.sum()
    return idx, weights


def interpolate_coeffs(
    params: np.ndarray,
    coeffs: np.ndarray,
    target: np.ndarray,
    k: int,
) -> np.ndarray:
    idx, weights = knn_indices_weights(params, target, k)
    if idx.size == 1:
        return coeffs[int(idx[0])]
    return np.tensordot(weights, coeffs[idx], axes=(0, 0))


def interpolate_latent_stats(
    params: np.ndarray,
    latent_stats: np.ndarray,
    target: np.ndarray,
    k: int,
) -> np.ndarray:
    idx, weights = knn_indices_weights(params, target, k)
    if idx.size == 1:
        return latent_stats[int(idx[0])]
    return np.tensordot(weights, latent_stats[idx], axes=(0, 0))


def integrate_latent(z0: np.ndarray, coeffs: np.ndarray, terms, dt: float, steps: int) -> np.ndarray:
    z = np.empty((steps + 1, z0.size), dtype=z0.dtype)
    z[0] = z0
    if steps == 0:
        return z

    def rhs(z_state: np.ndarray) -> np.ndarray:
        theta = evaluate_terms(z_state, terms)
        return theta @ coeffs

    def dopri_step(z_state: np.ndarray, h: float) -> Tuple[np.ndarray, np.ndarray]:
        k1 = rhs(z_state)
        k2 = rhs(z_state + h * (1.0 / 5.0) * k1)
        k3 = rhs(z_state + h * ((3.0 / 40.0) * k1 + (9.0 / 40.0) * k2))
        k4 = rhs(
            z_state
            + h
            * (
                (44.0 / 45.0) * k1
                + (-56.0 / 15.0) * k2
                + (32.0 / 9.0) * k3
            )
        )
        k5 = rhs(
            z_state
            + h
            * (
                (19372.0 / 6561.0) * k1
                + (-25360.0 / 2187.0) * k2
                + (64448.0 / 6561.0) * k3
                + (-212.0 / 729.0) * k4
            )
        )
        k6 = rhs(
            z_state
            + h
            * (
                (9017.0 / 3168.0) * k1
                + (-355.0 / 33.0) * k2
                + (46732.0 / 5247.0) * k3
                + (49.0 / 176.0) * k4
                + (-5103.0 / 18656.0) * k5
            )
        )
        k7 = rhs(
            z_state
            + h
            * (
                (35.0 / 384.0) * k1
                + (500.0 / 1113.0) * k3
                + (125.0 / 192.0) * k4
                + (-2187.0 / 6784.0) * k5
                + (11.0 / 84.0) * k6
            )
        )

        z_5th = z_state + h * (
            (35.0 / 384.0) * k1
            + (500.0 / 1113.0) * k3
            + (125.0 / 192.0) * k4
            + (-2187.0 / 6784.0) * k5
            + (11.0 / 84.0) * k6
        )
        z_4th = z_state + h * (
            (5179.0 / 57600.0) * k1
            + (7571.0 / 16695.0) * k3
            + (393.0 / 640.0) * k4
            + (-92097.0 / 339200.0) * k5
            + (187.0 / 2100.0) * k6
            + (1.0 / 40.0) * k7
        )
        err = z_5th - z_4th
        return z_5th, err

    rtol = 1.0e-6
    atol = 1.0e-9
    safety = 0.9
    min_scale = 0.2
    max_scale = 5.0
    min_h = max(1.0e-14, 1.0e-12 * dt)

    t_current = 0.0
    z_current = z0.astype(float, copy=True)
    h = dt

    for out_idx in range(1, steps + 1):
        t_target = out_idx * dt
        guard = 0
        while t_current < t_target:
            guard += 1
            if guard > 100000:
                raise RuntimeError("RK45 integration exceeded maximum substeps")

            h_step = min(h, t_target - t_current)
            z_trial, err = dopri_step(z_current, h_step)
            scale = atol + rtol * np.maximum(np.abs(z_current), np.abs(z_trial))
            err_norm = np.sqrt(np.mean((err / scale) ** 2))

            if err_norm <= 1.0:
                t_current += h_step
                z_current = z_trial
                if err_norm == 0.0:
                    h = min(dt, h_step * max_scale)
                else:
                    h = min(
                        dt,
                        h_step
                        * np.clip(safety * err_norm ** (-1.0 / 5.0), min_scale, max_scale),
                    )
            else:
                h = h_step * max(min_scale, safety * err_norm ** (-1.0 / 5.0))
                if h < min_h:
                    raise RuntimeError(
                        "RK45 integration step size underflow; latent dynamics may be unstable"
                    )

        z[out_idx] = z_current.astype(z0.dtype, copy=False)

    return z


def decode_series(
    model: AutoEncoder,
    z: np.ndarray,
    mean: np.ndarray,
    std: np.ndarray,
    device: torch.device, # type: ignore
    batch_size: int,
) -> np.ndarray:
    require_torch()
    model.eval()
    u_list = []
    with torch.no_grad():
        for i in range(0, z.shape[0], batch_size):
            batch = torch.from_numpy(z[i : i + batch_size]).float().to(device)
            u_norm = model.decode(batch).cpu().numpy()
            u_list.append(u_norm)
    u_norm = np.vstack(u_list)
    return u_norm * std + mean


def predict_solution(
    model: AutoEncoder,
    mean: np.ndarray,
    std: np.ndarray,
    params: np.ndarray,
    coeffs: np.ndarray,
    latent_means: np.ndarray,
    latent_stds: np.ndarray,
    terms,
    x: np.ndarray,
    t: np.ndarray,
    a: float,
    w: float,
    knn: int,
    device: torch.device, # type: ignore
    batch_size: int,
    drop_endpoint: bool,
) -> np.ndarray:
    if t.size < 2:
        raise RuntimeError("Time grid must contain at least two points")
    target = np.array([a, w], dtype=float)
    dt = t[1] - t[0]
    steps = t.size - 1
    coeffs_interp = interpolate_coeffs(params, coeffs, target, knn)
    if latent_means.ndim == 1 and latent_stds.ndim == 1:
        z_mean_interp = latent_means
        z_std_interp = np.maximum(latent_stds, 1.0e-8)
    else:
        z_mean_interp = interpolate_latent_stats(params, latent_means, target, knn)
        z_std_interp = np.maximum(
            interpolate_latent_stats(params, latent_stds, target, knn),
            1.0e-8,
        )

    u0 = initial_condition(x, a, w)
    if not drop_endpoint:
        u0[-1] = u0[0]
    z0 = encode_series(model, u0[None, :], mean, std, device, batch_size)[0]
    z0_hat = (z0 - z_mean_interp) / z_std_interp

    z_hat = integrate_latent(z0_hat, coeffs_interp, terms, dt, steps)
    z = z_hat * z_std_interp + z_mean_interp
    u_pred = decode_series(model, z, mean, std, device, batch_size)
    if not drop_endpoint:
        u_pred[:, -1] = u_pred[:, 0]
    return u_pred


def max_relative_error_percent(u_true: np.ndarray, u_pred: np.ndarray) -> float:
    if u_true.shape != u_pred.shape:
        raise ValueError(
            f"Shape mismatch for error computation: {u_true.shape} vs {u_pred.shape}"
        )
    denom = np.linalg.norm(u_true, axis=1)
    denom = np.maximum(denom, 1.0e-12)
    rel_over_time = np.linalg.norm(u_pred - u_true, axis=1) / denom
    return float(np.max(rel_over_time) * 100.0)


def build_error_map(
    dataset_dir: Path,
    rows: Sequence[Tuple[str, float, float]],
    model: AutoEncoder,
    mean: np.ndarray,
    std: np.ndarray,
    params: np.ndarray,
    coeffs: np.ndarray,
    latent_means: np.ndarray,
    latent_stds: np.ndarray,
    terms,
    x: np.ndarray,
    t: np.ndarray,
    drop_endpoint: bool,
    time_stride: int,
    knn: int,
    device: torch.device, # type: ignore
    batch_size: int,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    a_values = np.array(sorted({a for _, a, _ in rows}), dtype=float)
    w_values = np.array(sorted({w for _, _, w in rows}), dtype=float)
    a_index = {float(a): j for j, a in enumerate(a_values)}
    w_index = {float(w): i for i, w in enumerate(w_values)}
    error_grid = np.full((w_values.size, a_values.size), np.nan, dtype=float)

    for filename, a, w in tqdm(rows, desc="Building LaSDI error map"):
        _, _, u_true = load_series(dataset_dir, filename, drop_endpoint, time_stride)
        u_pred = predict_solution(
            model,
            mean,
            std,
            params,
            coeffs,
            latent_means,
            latent_stds,
            terms,
            x,
            t,
            a,
            w,
            knn,
            device,
            batch_size,
            drop_endpoint,
        )
        error_grid[w_index[float(w)], a_index[float(a)]] = max_relative_error_percent(
            u_true,
            u_pred,
        )

    return a_values, w_values, error_grid


def cell_edges(values: np.ndarray) -> np.ndarray:
    if values.size == 1:
        v = float(values[0])
        return np.array([v - 0.5, v + 0.5], dtype=float)
    mids = 0.5 * (values[:-1] + values[1:])
    left = values[0] - 0.5 * (values[1] - values[0])
    right = values[-1] + 0.5 * (values[-1] - values[-2])
    return np.concatenate([[left], mids, [right]])


def plot_lasdi_error_map(
    a_values: np.ndarray,
    w_values: np.ndarray,
    error_grid: np.ndarray,
    train_params: np.ndarray,
    output_path: Path,
    vmax: float,
) -> None:
    try:
        import matplotlib.pyplot as plt
        from matplotlib.patches import Rectangle
    except Exception as exc:
        raise RuntimeError(
            "matplotlib is required to save the LaSDI error-map figure."
        ) from exc

    output_path.parent.mkdir(parents=True, exist_ok=True)
    a_edges = cell_edges(a_values)
    w_edges = cell_edges(w_values)

    fig, ax = plt.subplots(figsize=(8.2, 6.0))
    mesh = ax.pcolormesh(
        a_edges,
        w_edges,
        error_grid,
        shading="auto",
        cmap="coolwarm",
        vmin=0.0,
        vmax=vmax,
    )

    for i, w in enumerate(w_values):
        for j, a in enumerate(a_values):
            value = error_grid[i, j]
            if np.isnan(value):
                continue
            ax.text(
                float(a),
                float(w),
                f"{value:.1f}",
                ha="center",
                va="center",
                fontsize=5,
                color="black",
            )

    a_index = {float(a): j for j, a in enumerate(a_values)}
    w_index = {float(w): i for i, w in enumerate(w_values)}
    for a, w in train_params:
        j = a_index.get(float(a))
        i = w_index.get(float(w))
        if j is None or i is None:
            continue
        rect = Rectangle(
            (a_edges[j], w_edges[i]),
            a_edges[j + 1] - a_edges[j],
            w_edges[i + 1] - w_edges[i],
            fill=False,
            edgecolor="black",
            linewidth=1.2,
        )
        ax.add_patch(rect)

    ax.set_xlabel("a")
    ax.set_ylabel("w")
    ax.set_title("LaSDI")
    ax.set_xlim(a_edges[0], a_edges[-1])
    ax.set_ylim(w_edges[0], w_edges[-1])
    cbar = fig.colorbar(mesh, ax=ax, pad=0.02)
    cbar.set_label("Maximum relative error (%)")
    fig.tight_layout()
    fig.savefig(output_path, dpi=300)
    plt.close(fig)


def save_model(
    model_dir: Path,
    model: AutoEncoder,
    ae_cfg: AEConfig,
    train_cfg: TrainConfig,
    mean: np.ndarray,
    std: np.ndarray,
    params: np.ndarray,
    coeffs: np.ndarray,
    latent_means: np.ndarray,
    latent_stds: np.ndarray,
    terms,
    x: np.ndarray,
    t: np.ndarray,
):
    model_dir.mkdir(parents=True, exist_ok=True)
    torch.save(model.state_dict(), model_dir / "ae.pt")
    np.savez(model_dir / "normalization.npz", mean=mean, std=std)
    np.save(model_dir / "params.npy", params)
    np.save(model_dir / "sindy_coeffs.npy", coeffs)
    np.savez(model_dir / "latent_scaling.npz", mean=latent_means, std=latent_stds)
    np.savez(model_dir / "grid.npz", x=x, t=t)
    with (model_dir / "sindy_terms.json").open("w", encoding="utf-8") as handle:
        json.dump(term_names(terms), handle, indent=2)

    config = {
        "input_dim": int(ae_cfg.input_dim),
        "latent_dim": int(ae_cfg.latent_dim),
        "hidden_sizes": list(ae_cfg.hidden_sizes),
        "activation": ae_cfg.activation,
        "epochs": int(train_cfg.epochs),
        "batch_size": int(train_cfg.batch_size),
        "lr": float(train_cfg.lr),
        "weight_decay": float(train_cfg.weight_decay),
        "time_stride": int(train_cfg.time_stride),
        "drop_endpoint": bool(train_cfg.drop_endpoint),
        "sindy_degree": int(train_cfg.sindy_degree),
        "sindy_threshold": float(train_cfg.sindy_threshold),
        "sindy_max_iter": int(train_cfg.sindy_max_iter),
        "sindy_ridge": float(train_cfg.sindy_ridge),
        "latent_standardized_for_sindy": True,
        "latent_scaling_scope": "global",
    }
    with (model_dir / "config.json").open("w", encoding="utf-8") as handle:
        json.dump(config, handle, indent=2)


def load_model(model_dir: Path, device: torch.device): # type: ignore
    require_torch()
    with (model_dir / "config.json").open("r", encoding="utf-8") as handle:
        cfg = json.load(handle)
    ae_cfg = AEConfig(
        input_dim=cfg["input_dim"],
        latent_dim=cfg["latent_dim"],
        hidden_sizes=cfg["hidden_sizes"],
        activation=cfg["activation"],
    )
    model = AutoEncoder(ae_cfg).to(device)
    model.load_state_dict(torch.load(model_dir / "ae.pt", map_location=device))
    model.eval()

    norm = np.load(model_dir / "normalization.npz")
    mean = norm["mean"]
    std = norm["std"]
    params = np.load(model_dir / "params.npy")
    coeffs = np.load(model_dir / "sindy_coeffs.npy")
    latent_scaling_path = model_dir / "latent_scaling.npz"
    if latent_scaling_path.exists():
        latent_scaling = np.load(latent_scaling_path)
        latent_means = latent_scaling["mean"]
        latent_stds = latent_scaling["std"]
    else:
        latent_means = np.zeros((ae_cfg.latent_dim,), dtype=float)
        latent_stds = np.ones((ae_cfg.latent_dim,), dtype=float)
    grid = np.load(model_dir / "grid.npz")
    x = grid["x"]
    t = grid["t"]
    with (model_dir / "sindy_terms.json").open("r", encoding="utf-8") as handle:
        term_labels = json.load(handle)

    terms = build_terms(ae_cfg.latent_dim, cfg["sindy_degree"])
    if term_names(terms) != term_labels:
        raise RuntimeError("Stored SINDy terms do not match generated terms")

    return model, mean, std, params, coeffs, latent_means, latent_stds, terms, x, t, cfg


def train_pipeline(args: argparse.Namespace) -> None:
    require_torch()
    dataset_dir = Path(args.dataset_dir)
    model_dir = Path(args.model_dir)
    rows = load_index(dataset_dir)
    learning_rows = select_grid_rows(rows)
    if not learning_rows:
        raise RuntimeError("Dataset index is empty")
    print(
        "Using "
        f"{len(learning_rows)} training cases "
        f"({GRID_SAMPLES_PER_AXIS}x{GRID_SAMPLES_PER_AXIS} subsampled grid)"
    )
    for _, a, w in learning_rows:
        print(f"  selected (a={a:.6f}, w={w:.6f})")

    if args.time_stride < 1:
        raise ValueError("time_stride must be >= 1")
    if args.error_map_knn < 1:
        raise ValueError("error_map_knn must be >= 1")
    if args.error_map_vmax <= 0.0:
        raise ValueError("error_map_vmax must be > 0")
    if args.weight_decay < 0.0:
        raise ValueError("weight_decay must be >= 0")
    if args.sindy_ridge < 0.0:
        raise ValueError("sindy_ridge must be >= 0")

    params, x, t, u_snapshots = collect_snapshots(
        dataset_dir,
        learning_rows,
        args.time_stride,
        args.drop_endpoint,
    )
    if t.size < 2:
        raise RuntimeError("Time grid must contain at least two points")
    dt = t[1] - t[0]

    u_norm, mean, std = normalize_data(u_snapshots)

    ae_cfg = AEConfig(
        input_dim=u_norm.shape[1],
        latent_dim=args.latent_dim,
        hidden_sizes=tuple(args.hidden_sizes),
        activation=args.activation,
    )
    train_cfg = TrainConfig(
        epochs=args.epochs,
        batch_size=args.batch_size,
        lr=args.lr,
        weight_decay=args.weight_decay,
        time_stride=args.time_stride,
        drop_endpoint=args.drop_endpoint,
        sindy_degree=args.sindy_degree,
        sindy_threshold=args.sindy_threshold,
        sindy_max_iter=args.sindy_max_iter,
        sindy_ridge=args.sindy_ridge,
    )

    device = torch.device("cpu" if args.cpu or not torch.cuda.is_available() else "cuda")
    model = train_autoencoder(u_norm, ae_cfg, train_cfg, device)
    print("device:", device)

    encoded_series_list = []
    params_used = []
    for filename, a, w in learning_rows:
        _, _, u_series = load_series(dataset_dir, filename, args.drop_endpoint, args.time_stride)
        z = encode_series(model, u_series, mean, std, device, args.batch_size)
        encoded_series_list.append(z)
        params_used.append([a, w])

    z_all = np.vstack(encoded_series_list)
    latent_means = z_all.mean(axis=0)
    latent_stds = np.maximum(z_all.std(axis=0), 1.0e-8)
    print("Global latent scaling stats computed across all learning cases.")
    print("max|z_hat(all)|", np.max(np.abs((z_all - latent_means) / latent_stds)))

    coeffs_list = []
    for (_, a, w), z in zip(learning_rows, encoded_series_list):
        xi, terms = fit_sindy(
            z,
            dt,
            args.sindy_degree,
            args.sindy_threshold,
            args.sindy_max_iter,
            args.sindy_ridge,
            latent_means,
            latent_stds,
        )
        coeffs_list.append(xi)
        z_hat = (z - latent_means) / latent_stds
        print(f"SINDy fit for a={a:.3f}, w={w:.3f} terms={xi.shape[0]}")
        print("max|z_hat|", np.max(np.abs(z_hat)))
        print("max|dzdt_hat|", np.max(np.abs(time_derivative(z_hat, dt))))
        print("||Xi||", np.linalg.norm(xi))

    coeffs = np.stack(coeffs_list, axis=0)
    params_used = np.asarray(params_used)
    print(np.linalg.norm(coeffs, axis=(1, 2)))

    save_model(
        model_dir,
        model,
        ae_cfg,
        train_cfg,
        mean,
        std,
        params_used,
        coeffs,
        latent_means,
        latent_stds,
        terms,
        x,
        t,
    )
    print(f"Saved model to {model_dir}")

    if not args.no_error_map:
        error_map_path = (
            Path(args.error_map_output)
            if args.error_map_output
            else model_dir / "lasdi_error_map.png"
        )
        a_values, w_values, error_grid = build_error_map(
            dataset_dir,
            rows,
            model,
            mean,
            std,
            params_used,
            coeffs,
            latent_means,
            latent_stds,
            terms,
            x,
            t,
            args.drop_endpoint,
            args.time_stride,
            args.error_map_knn,
            device,
            args.batch_size,
        )
        plot_lasdi_error_map(
            a_values,
            w_values,
            error_grid,
            params_used,
            error_map_path,
            args.error_map_vmax,
        )
        np.savez(
            error_map_path.with_suffix(".npz"),
            a_values=a_values,
            w_values=w_values,
            max_rel_err_percent=error_grid,
            train_params=params_used,
        )
        print(f"Saved LaSDI error map figure to {error_map_path}")
    else:
        print("Skipped LaSDI error map output (--no-error-map).")


def predict_pipeline(args: argparse.Namespace) -> None:
    require_torch()
    model_dir = Path(args.model_dir)
    device = torch.device("cpu" if args.cpu or not torch.cuda.is_available() else "cuda")
    model, mean, std, params, coeffs, latent_means, latent_stds, terms, x, t, cfg = load_model(model_dir, device)

    a = float(args.a)
    w = float(args.w)
    u_pred = predict_solution(
        model,
        mean,
        std,
        params,
        coeffs,
        latent_means,
        latent_stds,
        terms,
        x,
        t,
        a,
        w,
        args.knn,
        device,
        args.batch_size,
        bool(cfg["drop_endpoint"]),
    )

    out = Path(args.output)
    np.savez(out, a=a, w=w, x=x, t=t, u=u_pred)
    print(f"Saved prediction to {out}")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Baseline LaSDI for Burgers.")
    sub = parser.add_subparsers(dest="command", required=True)

    train = sub.add_parser("train", help="Train AE + SINDy on dataset")
    train.add_argument(
        "--dataset-dir",
        default=str(DEFAULT_DATASET_DIR),
        help="Dataset directory",
    )
    train.add_argument(
        "--model-dir",
        default=str(DEFAULT_MODEL_DIR),
        help="Output model directory",
    )
    train.add_argument("--latent-dim", type=int, default=5, help="Latent dimension")
    train.add_argument(
        "--hidden-sizes",
        type=lambda s: [int(v) for v in s.split(",") if v],
        default=[100],
        help="Comma-separated hidden sizes (e.g., 100,100)",
    )
    train.add_argument("--activation", type=str, default="tanh", help="Activation")
    train.add_argument("--epochs", type=int, default=5000, help="Training epochs")
    train.add_argument("--batch-size", type=int, default=512, help="Batch size")
    train.add_argument("--lr", type=float, default=1.0e-3, help="Learning rate")
    train.add_argument(
        "--weight-decay",
        type=float,
        default=1.0e-6,
        help="Adam weight decay",
    )
    train.add_argument("--time-stride", type=int, default=1, help="Time stride")
    train.add_argument(
        "--drop-endpoint",
        action="store_true",
        help="Drop periodic endpoint before training",
    )
    train.add_argument("--sindy-degree", type=int, default=1, help="SINDy degree")
    train.add_argument(
        "--sindy-threshold",
        "--sindy-threshould",
        dest="sindy_threshold",
        type=float,
        default=0.05,
        help="STLSQ threshold",
    )
    train.add_argument("--sindy-max-iter", type=int, default=10, help="STLSQ iterations")
    train.add_argument(
        "--sindy-ridge",
        type=float,
        default=1.0e-5,
        help="Ridge regularization for STLSQ",
    )
    train.add_argument(
        "--no-error-map",
        action="store_true",
        help="Skip LaSDI error-map figure output after training",
    )
    train.add_argument(
        "--error-map-output",
        type=str,
        default="",
        help="Output path for LaSDI error-map image (default: <model-dir>/lasdi_error_map.png)",
    )
    train.add_argument(
        "--error-map-knn",
        type=int,
        default=1,
        help="kNN neighbors used when building LaSDI error map",
    )
    train.add_argument(
        "--error-map-vmax",
        type=float,
        default=5.0,
        help="Colorbar max value (%) for LaSDI error map",
    )
    train.add_argument("--cpu", action="store_true", help="Force CPU")

    predict = sub.add_parser("predict", help="Predict for a new (a, w)")
    predict.add_argument(
        "--model-dir",
        default=str(DEFAULT_MODEL_DIR),
        help="Model directory",
    )
    predict.add_argument("--a", type=float, required=True, help="Amplitude parameter a")
    predict.add_argument("--w", type=float, required=True, help="Width parameter w")
    predict.add_argument("--knn", type=int, default=1, help="kNN neighbors for coeffs")
    predict.add_argument(
        "--output",
        type=str,
        default="prediction.npz",
        help="Output .npz file",
    )
    predict.add_argument("--batch-size", type=int, default=512, help="Batch size")
    predict.add_argument("--cpu", action="store_true", help="Force CPU")

    return parser.parse_args()


def main() -> None:
    args = parse_args()
    if args.command == "train":
        train_pipeline(args)
    elif args.command == "predict":
        predict_pipeline(args)


if __name__ == "__main__":
    main()
